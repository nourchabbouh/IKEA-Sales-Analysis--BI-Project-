{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9RWKcjVOaNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f70e3d5f-ebca-4792-a384-f105106076af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting from csv to JSON**"
      ],
      "metadata": {
        "id": "qMi-i_jbn5Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = '/content/drive/My Drive/ikea/ikea_products.csv'\n",
        "products = pd.read_csv(file_path)\n",
        "products.to_json('productsjson.json', orient='records', date_format='iso')\n",
        "files.download('productsjson.json')\n",
        "\n"
      ],
      "metadata": {
        "id": "v7FHgYdqSZDt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a935bc76-5c7d-488e-e62e-a2b686f57353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9720abed-d3b7-468d-bfb3-6bcc7e51799f\", \"productsjson.json\", 22086)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/ikea/inventory.csv'\n",
        "inventory = pd.read_csv(file_path)\n",
        "inventory.to_json('inventoryjson.json', orient='records', date_format='iso')\n",
        "files.download('inventoryjson.json')\n"
      ],
      "metadata": {
        "id": "aFMTpY9dWMg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b072f271-2537-49ef-cb74-0d4f7b9331f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_96d7376c-cbb5-418f-a2ab-2de7df3205ce\", \"inventoryjson.json\", 13934)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/ikea/sales.csv'\n",
        "sales = pd.read_csv(file_path)\n",
        "sales.to_json('salesjson.json', orient='records', date_format='iso')\n",
        "    # Step 4: Download the JSON file (optional in Colab)\n",
        "files.download('salesjson.json')\n",
        "print(sales)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "2bG4iwfEXAG0",
        "outputId": "2efc0bb1-a1e0-4597-cf90-0fb0868fe5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c70fb703-49ee-4f90-9e60-f11a1daba9ec\", \"salesjson.json\", 7139687)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       order_id  order_date product_id  qty  discount_percentage  unit_price  \\\n",
            "0        IN-897  2021-08-22       P-75    4                  0.5      249.00   \n",
            "1       IN-4441  2023-03-17      P-134    2                  0.3       29.99   \n",
            "2       IN-4746  2023-10-02      P-131    4                  0.5      699.00   \n",
            "3       IN-5734  2022-09-20        P-4    4                  0.6       79.99   \n",
            "4       IN-6742  2021-11-25       P-40    4                  0.5       34.99   \n",
            "...         ...         ...        ...  ...                  ...         ...   \n",
            "50451   IN-8295  2021-06-06       P-37    2                  0.2      129.00   \n",
            "50452   IN-9246  2021-11-17      P-137    3                  0.3       79.99   \n",
            "50453  IN-10568  2022-07-04        P-4    4                  0.4       79.99   \n",
            "50454  IN-11497  2022-05-25      P-107    2                  0.2      199.00   \n",
            "50455  IN-15707  2023-03-04      P-172    1                  0.1      899.00   \n",
            "\n",
            "      store_id  \n",
            "0         IK-1  \n",
            "1         IK-1  \n",
            "2         IK-1  \n",
            "3         IK-1  \n",
            "4         IK-1  \n",
            "...        ...  \n",
            "50451   IK-101  \n",
            "50452   IK-101  \n",
            "50453   IK-101  \n",
            "50454   IK-101  \n",
            "50455   IK-101  \n",
            "\n",
            "[50456 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/ikea/ikea_stores.csv'\n",
        "stores = pd.read_csv(file_path)\n",
        "stores.to_json('storesjson.json', orient='records', date_format='iso')\n",
        "files.download('storesjson.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-G5WePIvXPcL",
        "outputId": "52c80492-d05b-44d7-b398-1ebf1d14f0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_419d4712-1784-4604-9d84-d4d9c8b094e6\", \"storesjson.json\", 9350)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing data transformation**"
      ],
      "metadata": {
        "id": "vVOwZIjSb_te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# load JSON files into pandas Dataframes\n",
        "sales_df = pd.read_json('salesjson.json')\n",
        "inventory_df = pd.read_json('inventoryjson.json')\n",
        "products_df = pd.read_json('productsjson.json')\n",
        "stores_df = pd.read_json('storesjson.json')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pZJZPaM0T24D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "b3937e1d-4524-49ef-af92-d5f6b1390c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "File storesjson.json does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9840cf04c488>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minventory_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inventoryjson.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mproducts_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'productsjson.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstores_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'storesjson.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mconvert_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     json_reader = JsonReader(\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ujson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         ):\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {filepath_or_buffer} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File storesjson.json does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize date format to YYYY-MM-DD in sales\n",
        "def date_format(date_series):\n",
        " return pd.to_datetime(date_series).dt.strftime('%y-%m-%d')\n",
        "sales_df['order_date'] = date_format(sales_df['order_date'])\n",
        "\n",
        "# Remove duplicates from each DataFrames\n",
        "sales_df_no_duplicates = sales_df.drop_duplicates()\n",
        "inventory_df_no_duplicates = inventory_df.drop_duplicates()\n",
        "products_df_no_duplicates = products_df.drop_duplicates()\n",
        "stores_df_no_duplicates = stores_df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "T1iePCMab70p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**from 2019-2023**"
      ],
      "metadata": {
        "id": "FY-eS8XavWQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate revenue and add it as a new column\n",
        "sales_df['revenue'] = sales_df['qty'] * sales_df['unit_price'] * (1 - sales_df['discount_percentage'] )\n",
        "\n",
        "total_revenue = sales_df['revenue'].sum()\n",
        "# Add the total revenue row to the DataFrame\n",
        "total_revenue_row = pd.DataFrame({'qty': ['Total'], 'unit_price': [None], 'discount_percentage': [None],\n",
        "                                  'revenue': [total_revenue]})\n",
        "sales_df = pd.concat([sales_df, total_revenue_row], ignore_index=True)\n",
        "print(sales_df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUYcjksZevGR",
        "outputId": "92fdab89-7b28-446b-d085-1bfcd7ef411f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       order_id  order_date product_id    qty  discount_percentage  \\\n",
            "0        IN-897  2021-08-22       P-75      4                  0.5   \n",
            "1       IN-4441  2023-03-17      P-134      2                  0.3   \n",
            "2       IN-4746  2023-10-02      P-131      4                  0.5   \n",
            "3       IN-5734  2022-09-20        P-4      4                  0.6   \n",
            "4       IN-6742  2021-11-25       P-40      4                  0.5   \n",
            "...         ...         ...        ...    ...                  ...   \n",
            "50452   IN-9246  2021-11-17      P-137      3                  0.3   \n",
            "50453  IN-10568  2022-07-04        P-4      4                  0.4   \n",
            "50454  IN-11497  2022-05-25      P-107      2                  0.2   \n",
            "50455  IN-15707  2023-03-04      P-172      1                  0.1   \n",
            "50456       NaN         NaN        NaN  Total                  NaN   \n",
            "\n",
            "       unit_price store_id       revenue  \n",
            "0          249.00     IK-1  4.980000e+02  \n",
            "1           29.99     IK-1  4.198600e+01  \n",
            "2          699.00     IK-1  1.398000e+03  \n",
            "3           79.99     IK-1  1.279840e+02  \n",
            "4           34.99     IK-1  6.998000e+01  \n",
            "...           ...      ...           ...  \n",
            "50452       79.99   IK-101  1.679790e+02  \n",
            "50453       79.99   IK-101  1.919760e+02  \n",
            "50454      199.00   IK-101  3.184000e+02  \n",
            "50455      899.00   IK-101  8.091000e+02  \n",
            "50456         NaN      NaN  1.222055e+07  \n",
            "\n",
            "[50457 rows x 8 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-1a56c59f8a1a>:8: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  sales_df = pd.concat([sales_df, total_revenue_row], ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Merge the sales data with store data on 'store_id'\n",
        "merged_data = pd.merge(sales_df, stores_df, on='store_id', how='inner')\n",
        "\n",
        "# Group by 'country' (or 'city' if you prefer) and calculate the total revenue\n",
        "sales_by_region = merged_data.groupby('country')['revenue'].sum().reset_index()\n",
        "\n",
        "# Sort the results by revenue to identify the top-performing regions\n",
        "sales_by_region_sorted = sales_by_region.sort_values(by='revenue', ascending=False)\n",
        "\n",
        "# Display the result\n",
        "print(sales_by_region_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "frxww76bi4L9",
        "outputId": "e6a55b75-0ee0-4237-b1a5-39a4eb0aebdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'stores_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5350add3efb5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Merge the sales data with store data on 'store_id'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmerged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstores_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'store_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Group by 'country' (or 'city' if you prefer) and calculate the total revenue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stores_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the sorted data by date\n",
        "\n",
        "import pandas as pd\n",
        "sorted_sales_data = sales_df.sort_values(by='order_date', ascending=True)  # ascending=False for descending order\n",
        "print(sorted_sales_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ks_d2ELlV8P",
        "outputId": "38778f2b-1899-4c20-cbb5-ede8085655d4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       order_id order_date product_id    qty  discount_percentage  unit_price  \\\n",
            "8982   IN-50296   19-01-01       P-12      1                  0.1       69.99   \n",
            "9412   IN-50169   19-01-01        P-3      4                  0.4      199.00   \n",
            "28185  IN-49704   19-01-01       P-11      4                  0.4       24.99   \n",
            "23966  IN-45293   19-01-01        P-9      1                  0.1      249.00   \n",
            "28523  IN-44526   19-01-01       P-15      1                  0.1      999.00   \n",
            "...         ...        ...        ...    ...                  ...         ...   \n",
            "25768  IN-14874   23-12-31      P-100      3                  0.3       12.99   \n",
            "31404  IN-35235   23-12-31       P-60      2                  0.2       15.00   \n",
            "31028  IN-37898   23-12-31       P-24      3                  0.3       49.99   \n",
            "34362  IN-38481   23-12-31       P-11      4                  0.4       24.99   \n",
            "50456       NaN        NaN        NaN  Total                  NaN         NaN   \n",
            "\n",
            "      store_id       revenue  \n",
            "8982      IK-7  6.299100e+01  \n",
            "9412      IK-7  4.776000e+02  \n",
            "28185    IK-20  5.997600e+01  \n",
            "23966    IK-17  2.241000e+02  \n",
            "28523    IK-21  8.991000e+02  \n",
            "...        ...           ...  \n",
            "25768    IK-19  2.727900e+01  \n",
            "31404    IK-23  2.400000e+01  \n",
            "31028    IK-23  1.049790e+02  \n",
            "34362    IK-25  5.997600e+01  \n",
            "50456      NaN  1.222055e+07  \n",
            "\n",
            "[50457 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All sales in 2023 , sorted by date**"
      ],
      "metadata": {
        "id": "p_3WfQlar4RS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming sales_df is already loaded with your data\n",
        "\n",
        "# Convert the 'order_date' column to datetime format if it's not already\n",
        "sales_df['order_date'] = pd.to_datetime(sales_df['order_date'])\n",
        "\n",
        "# Filter the data for the year 2023\n",
        "sales_2023 = sales_df[sales_df['order_date'].dt.year == 2023]\n",
        "\n",
        "# Sort the filtered data by 'order_date' in ascending order\n",
        "sales_2023_sorted = sales_2023.sort_values(by='order_date', ascending=True)  # Set ascending=False for descending order\n",
        "\n",
        "# Display the sorted DataFrame\n",
        "print(sales_2023_sorted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWm6nZXqrlNy",
        "outputId": "fa5a9077-3902-4962-82dd-9805b05f3ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-940aa894e743>:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  sales_df['order_date'] = pd.to_datetime(sales_df['order_date'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       order_id order_date product_id qty  discount_percentage  unit_price  \\\n",
            "31054  IN-44633 2023-01-19       P-11   1                  0.1       24.99   \n",
            "26804  IN-43488 2023-01-19       P-18   4                  0.4       45.00   \n",
            "12180  IN-47618 2023-01-19       P-18   2                  0.2       45.00   \n",
            "4394   IN-44672 2023-01-19       P-23   3                  0.4        9.99   \n",
            "23389  IN-47796 2023-01-19       P-22   3                  0.3      159.00   \n",
            "...         ...        ...        ...  ..                  ...         ...   \n",
            "49048  IN-14479 2023-12-23      P-110   4                  0.4      299.00   \n",
            "7059   IN-38614 2023-12-23       P-13   4                  0.6      699.00   \n",
            "4889   IN-40420 2023-12-23       P-22   1                  0.3      159.00   \n",
            "23525  IN-40001 2023-12-23       P-24   1                  0.1       49.99   \n",
            "39130  IN-19630 2023-12-23      P-145   4                  0.4      179.00   \n",
            "\n",
            "      store_id   revenue  \n",
            "31054    IK-23    22.491  \n",
            "26804    IK-19   108.000  \n",
            "12180     IK-9    72.000  \n",
            "4394      IK-4    17.982  \n",
            "23389    IK-17   333.900  \n",
            "...        ...       ...  \n",
            "49048    IK-94   717.600  \n",
            "7059      IK-5  1118.400  \n",
            "4889      IK-4   111.300  \n",
            "23525    IK-17    44.991  \n",
            "39130    IK-46   429.600  \n",
            "\n",
            "[1641 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sort countries by revenue in 2023**"
      ],
      "metadata": {
        "id": "sE9LH1yJusxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming sales_df and stores_df are already loaded\n",
        "\n",
        "# Merge the sales data with store data on 'store_id'\n",
        "merged_data = pd.merge(sales_df, stores_df, on='store_id', how='inner')\n",
        "\n",
        "# Convert the 'order_date' column to datetime format (if not already)\n",
        "merged_data['order_date'] = pd.to_datetime(merged_data['order_date'])\n",
        "\n",
        "# Filter the data for the year 2023\n",
        "merged_data_2023 = merged_data[merged_data['order_date'].dt.year == 2023]\n",
        "\n",
        "# Add a column for the year (2023)\n",
        "merged_data_2023['year'] = 2023\n",
        "\n",
        "# Group by 'country' and calculate the total revenue for 2023\n",
        "sales_by_region_2023 = merged_data_2023.groupby(['country', 'year'])['revenue'].sum().reset_index()\n",
        "\n",
        "# Sort the results by revenue to identify the top-performing regions\n",
        "sales_by_region_sorted = sales_by_region_2023.sort_values(by='revenue', ascending=False)\n",
        "\n",
        "# Display the result\n",
        "print(sales_by_region_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-WhI1NnsdRW",
        "outputId": "eb935720-fddd-464e-f9c0-be63706a109b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           country  year     revenue\n",
            "40   United States  2023  242700.238\n",
            "39  United Kingdom  2023   29352.606\n",
            "12         Germany  2023   11883.324\n",
            "6            China  2023   11222.905\n",
            "41         Vietnam  2023    9980.962\n",
            "4           Canada  2023    6966.921\n",
            "0        Australia  2023    6049.055\n",
            "34           Spain  2023    5852.768\n",
            "11          France  2023    5842.601\n",
            "35          Sweden  2023    5684.113\n",
            "15           India  2023    5504.694\n",
            "3           Brazil  2023    5165.987\n",
            "36     Switzerland  2023    4851.963\n",
            "13         Hungary  2023    4305.300\n",
            "7         Colombia  2023    3868.125\n",
            "25          Poland  2023    3579.854\n",
            "9          Denmark  2023    3308.933\n",
            "17           Italy  2023    3163.679\n",
            "21          Mexico  2023    3091.163\n",
            "30        Slovakia  2023    2716.117\n",
            "8   Czech Republic  2023    2521.128\n",
            "22         Morocco  2023    2244.855\n",
            "5            Chile  2023    2074.400\n",
            "26        Portugal  2023    1714.776\n",
            "10         Finland  2023    1678.655\n",
            "38          Turkey  2023    1528.427\n",
            "2          Belgium  2023    1489.770\n",
            "33     South Korea  2023    1408.431\n",
            "23     Netherlands  2023    1271.630\n",
            "14         Iceland  2023    1225.191\n",
            "24          Norway  2023    1217.679\n",
            "18           Japan  2023    1099.937\n",
            "20        Malaysia  2023    1025.620\n",
            "16       Indonesia  2023    1011.368\n",
            "37          Taiwan  2023     949.694\n",
            "19           Kenya  2023     942.900\n",
            "32    South Africa  2023     833.558\n",
            "29       Singapore  2023     794.667\n",
            "27         Romania  2023     747.984\n",
            "28    Saudi Arabia  2023     701.028\n",
            "1          Belarus  2023     591.539\n",
            "31        Slovenia  2023     534.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-a209ac9b8a02>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_data_2023['year'] = 2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyze Best-Selling Products in 2023**:\n",
        "Identify products with the highest revenue"
      ],
      "metadata": {
        "id": "UKXTvdTOhbPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Calculate revenue in the Sales table\n",
        "sales_2023['revenue'] = sales_2023['qty'] * sales_2023['unit_price'] * (1 - sales_df['discount_percentage'] / 100)\n",
        "\n",
        "# Aggregate total quantity sold and total revenue by product_id\n",
        "sales_summary = sales_2023.groupby('product_id').agg(\n",
        "    total_qty_sold=('qty', 'sum'),\n",
        "    total_revenue=('revenue', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Merge with the Product table for detailed analysis\n",
        "best_selling_products = pd.merge(sales_summary, products_df, on='product_id')\n",
        "\n",
        "# Sort by total revenue\n",
        "best_selling_products_sorted = best_selling_products.sort_values(\n",
        "    by='total_revenue', ascending=False\n",
        ")\n",
        "\n",
        "# Save the result\n",
        "best_selling_products_sorted.to_csv(\"best_selling_products.csv\", index=False)\n",
        "\n",
        "print(best_selling_products_sorted.head())\n"
      ],
      "metadata": {
        "id": "Oba4wwCV7uUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6e33b8-d07d-4eb4-f412-ffeae8b5b52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    product_id total_qty_sold total_revenue          product_name  \\\n",
            "56        P-15             79     78656.265          GRÖNLID Sofa   \n",
            "34        P-13             49     34142.655            KIVIK Sofa   \n",
            "54       P-148             29     28879.092            KIVIK Sofa   \n",
            "154       P-81             16     15920.064  KIVIK Sectional Sofa   \n",
            "78        P-17             57     15853.059            LAGAN Oven   \n",
            "\n",
            "        category subcategory  unit_pice  \n",
            "56   Living Room     Seating      999.0  \n",
            "34   Living Room     Seating      699.0  \n",
            "54   Living Room     Seating      999.0  \n",
            "154  Living Room     Seating      999.0  \n",
            "78       Kitchen  Appliances      279.0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-cae381195891>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sales_2023['revenue'] = sales_2023['qty'] * sales_2023['unit_price'] * (1 - sales_df['discount_percentage'] / 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***the top 10 products with the highest quantities sold***"
      ],
      "metadata": {
        "id": "CKiy4g_CjdDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Step 1: Group by product_id and sum qty\n",
        "best_selling = sales_2023.groupby('product_id')['qty'].sum().reset_index()\n",
        "best_selling.rename(columns={'qty': 'total_qty_sold'}, inplace=True)\n",
        "\n",
        "# Step 2: Merge with Product table for details\n",
        "best_selling = pd.merge(best_selling, products_df, on='product_id', how='left')\n",
        "\n",
        "# Step 3: Sort products by total quantities sold\n",
        "best_selling = best_selling.sort_values(by='total_qty_sold', ascending=False)\n",
        "\n",
        "# Save the result to a file\n",
        "best_selling.to_csv(\"best_selling_products.csv\", index=False)\n",
        "\n",
        "# Display the top 10 best-sellers\n",
        "print(best_selling.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a58YBDdjDGn",
        "outputId": "8f92b21f-b3bc-4a16-921a-8515abdd267a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    product_id total_qty_sold                 product_name         category  \\\n",
            "86         P-2             87            LACK Coffee Table        Furniture   \n",
            "89        P-22             79              SLÄKT Bed Frame  Kids' Furniture   \n",
            "56        P-15             79                 GRÖNLID Sofa      Living Room   \n",
            "45        P-14             78          RÅSKOG Utility Cart          Kitchen   \n",
            "90        P-23             77                   KUGGIS Box        Furniture   \n",
            "152        P-8             76          HEMNES Shoe Cabinet        Furniture   \n",
            "84        P-18             74                   IVAR Shelf        Furniture   \n",
            "23        P-12             73  TROFAST Storage Combination  Kids' Furniture   \n",
            "119        P-5             72               POÄNG Armchair      Living Room   \n",
            "91        P-24             71               MELLTORP Table          Kitchen   \n",
            "\n",
            "    subcategory  unit_pice  \n",
            "86      Surface      29.99  \n",
            "89      Bedding     159.00  \n",
            "56      Seating     999.00  \n",
            "45   Organizers      29.99  \n",
            "90      Storage       9.99  \n",
            "152     Storage      99.99  \n",
            "84      Storage      45.00  \n",
            "23      Storage      69.99  \n",
            "119     Seating      89.99  \n",
            "91      Surface      49.99  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**top-performing stores by revenue**\n",
        "\n"
      ],
      "metadata": {
        "id": "JzAy7BePwSbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Import Libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "# Step 3: Merge Datasets\n",
        "# Merge sales with store to link sales to store information\n",
        "sales_store_df = sales_2023.merge(stores_df, on='store_id')\n",
        "\n",
        "# Merge sales_store_df with product to link sales to product details\n",
        "sales_store_product_df = sales_store_df.merge(products_df, on='product_id')\n",
        "\n",
        "# Step 4: Calculate Metrics\n",
        "# Calculate the total price after discount\n",
        "sales_store_product_df['total_price'] = sales_store_product_df['unit_price'] * (1 - sales_store_product_df['discount_percentage'])\n",
        "# Aggregate data by store\n",
        "store_performance = sales_store_product_df.groupby(\n",
        "    ['store_id', 'store_name', 'city', 'country']\n",
        ").agg(\n",
        "    total_sales=('total_price', 'sum'),\n",
        "    total_quantity_sold=('product_id', 'count'),\n",
        "    avg_transaction_value=('total_price', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "# Sort by total sales\n",
        "store_performance_sorted = store_performance.sort_values(by='total_sales', ascending=False)\n",
        "\n",
        "# Display top-performing stores\n",
        "print(\"Top Performing Stores:\")\n",
        "print(store_performance_sorted.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fZhw4yQuqUF",
        "outputId": "9785baef-f59a-46c1-8f0b-7aa068ede632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Performing Stores:\n",
            "   store_id        store_name         city         country  total_sales  \\\n",
            "19    IK-25      IKEA Cardiff      Cardiff  United Kingdom     6969.756   \n",
            "57     IK-6       IKEA Boston       Boston   United States     6826.034   \n",
            "9     IK-16   IKEA Louisville   Louisville   United States     6678.111   \n",
            "8     IK-15  IKEA Los Angeles  Los Angeles   United States     6465.288   \n",
            "79     IK-8      IKEA Chicago      Chicago   United States     6444.696   \n",
            "\n",
            "    total_quantity_sold  avg_transaction_value  \n",
            "19                   50             139.395120  \n",
            "57                   52             131.269885  \n",
            "9                    59             113.188322  \n",
            "8                    57             113.426105  \n",
            "79                   48             134.264500  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Total revenue and quantity sold *by* categoty**\n"
      ],
      "metadata": {
        "id": "v4u0Y42rLpzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fusionner les données des ventes avec les produits pour obtenir les catégories\n",
        "merged_df = pd.merge(sales_2023, products_df, on='product_id', how='inner')\n",
        "\n",
        "# Calculer la revenue pour chaque vente : revenue = unit_price * (1 - discount_percentage)\n",
        "merged_df['revenue'] = merged_df['unit_price'] * (1 - merged_df['discount_percentage'])\n",
        "\n",
        "\n",
        "\n",
        "# Regrouper par category et calculer le total de la revenue et de la quantité vendue\n",
        "category_sales = merged_df.groupby('category').agg(\n",
        "    total_revenue=('revenue', 'sum'),\n",
        "    total_quantity_sold=('qty', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Trier les résultats par revenue ou quantity (selon l'analyse que vous souhaitez faire)\n",
        "category_sales_sorted = category_sales.sort_values(by='total_revenue', ascending=False)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(category_sales_sorted)\n",
        "\n",
        "# Enregistrer les résultats dans un fichier CSV si nécessaire\n",
        "category_sales_sorted.to_csv('/content/total_revenue_and_quantity_by_category_2023.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNY4uiTELGUI",
        "outputId": "875c44e0-f555-4527-a53d-178dfbce1a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           category  total_revenue total_quantity_sold\n",
            "9       Living Room      80675.505                 877\n",
            "1           Bedroom      26755.900                 434\n",
            "4         Furniture      16356.189                1190\n",
            "6           Kitchen      13711.519                 535\n",
            "5   Kids' Furniture      12314.768                 336\n",
            "10           Office      11966.028                 293\n",
            "11          Outdoor       2932.423                 115\n",
            "8          Lighting       1621.613                 114\n",
            "0          Bathroom       1006.593                  64\n",
            "2             Decor        823.072                  92\n",
            "3       Electronics        597.877                  44\n",
            "12             Pets        181.909                  29\n",
            "13          Storage         74.908                  45\n",
            "7           Laundry         15.162                  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inventory Status**"
      ],
      "metadata": {
        "id": "IXf7Fv5_E_aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "# Display the first few rows of the inventory data\n",
        "print(\"Original Inventory Table:\")\n",
        "print(inventory_df.head())\n",
        "\n",
        "# Check if the required columns exist\n",
        "if 'current_stock' in inventory_df.columns and 'reorder_level' in inventory_df.columns:\n",
        "    # Add the stock_status column\n",
        "    inventory_df['stock_status'] = inventory_df['current_stock'] / inventory_df['reorder_level']\n",
        "\n",
        "    # Handle cases where reorder_level is 0 to avoid division by zero\n",
        "    inventory_df['stock_status'] = inventory_df['stock_status'].replace([float('inf'), -float('inf')], 0)\n",
        "    inventory_df['stock_status'] = inventory_df['stock_status'].fillna(0)\n",
        "\n",
        "    # Save the updated table (optional)\n",
        "    inventory_df.to_csv('/content/updated_inventory.csv', index=False)\n",
        "\n",
        "    print(\"\\nUpdated Inventory Table with 'stock_status':\")\n",
        "    print(inventory_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-079dACdDv9f",
        "outputId": "3ff2f633-683b-4c6a-a4bd-f838a1ce4b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Inventory Table:\n",
            "   iventory_id product_id  current_stock  reorder_level\n",
            "0            1       P-46              5             15\n",
            "1            2       P-53              5             15\n",
            "2            3       P-45              6             15\n",
            "3            4       P-57              6             15\n",
            "4            5       P-62              6             15\n",
            "\n",
            "Updated Inventory Table with 'stock_status':\n",
            "     iventory_id product_id  current_stock  reorder_level  stock_status\n",
            "0              1       P-46              5             15      0.333333\n",
            "1              2       P-53              5             15      0.333333\n",
            "2              3       P-45              6             15      0.400000\n",
            "3              4       P-57              6             15      0.400000\n",
            "4              5       P-62              6             15      0.400000\n",
            "..           ...        ...            ...            ...           ...\n",
            "174          175       P-67            160             50      3.200000\n",
            "175          176      P-170            166             50      3.320000\n",
            "176          177        P-5            166             50      3.320000\n",
            "177          178       P-91            169             50      3.380000\n",
            "178          179      P-166            170             50      3.400000\n",
            "\n",
            "[179 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discount effectiveness**"
      ],
      "metadata": {
        "id": "2njrix90SPDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fusionner les données des ventes avec les produits en utilisant 'product_id'\n",
        "merge_df = pd.merge(sales_2023, products_df, on='product_id', how='inner')\n",
        "\n",
        "# Calculer la revenue pour chaque vente : revenue = unit_price * (1 - discount_percentage)\n",
        "merge_df['revenue'] = merge_df['unit_price'] * (1 - merge_df['discount_percentage'])\n",
        "# Regrouper par discount_percentage et calculer la revenue moyenne et la quantité totale vendue\n",
        "discount_effectiveness = merge_df.groupby('discount_percentage').agg(\n",
        "    average_revenue=('revenue', 'mean'),\n",
        "    total_quantity_sold=('qty', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Trier les résultats pour voir l'impact du discount sur les ventes (revenue et quantité)\n",
        "discount_effectiveness_sorted = discount_effectiveness.sort_values(by='average_revenue', ascending=False)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(discount_effectiveness_sorted)\n",
        "\n",
        "# Enregistrer les résultats dans un fichier CSV si nécessaire\n",
        "discount_effectiveness_sorted.to_csv('/content/discount_effectiveness_with_quantity_2023.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybeC3jNoOVXC",
        "outputId": "2df10c4a-1191-4769-d8bc-8e6d7c41f5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   discount_percentage  average_revenue total_quantity_sold\n",
            "0                  0.1       127.598612                 348\n",
            "1                  0.2       112.944755                 655\n",
            "2                  0.3        98.479264                1189\n",
            "3                  0.4        90.002519                1650\n",
            "5                  0.6        71.944108                 138\n",
            "4                  0.5        53.101628                 139\n",
            "6                  0.7        37.139000                  60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Average Quantity and Range of Quantity Sold**"
      ],
      "metadata": {
        "id": "9Dkwdr8FUw_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge_df = pd.merge(sales_2023, products_df, on='product_id', how='inner')\n",
        "\n",
        "# Calculer la revenue pour chaque vente : revenue = unit_price * (1 - discount_percentage)\n",
        "merge_df['revenue'] = merge_df['unit_price'] * (1 - merge_df['discount_percentage'])\n",
        "\n",
        "# Calculer la quantité moyenne et le range de la quantité vendue (min, max)\n",
        "quantity_insights = merge_df.groupby('product_id').agg(\n",
        "    average_quantity_sold=('qty', 'mean'),\n",
        "    min_quantity_sold=('qty', 'min'),\n",
        "    max_quantity_sold=('qty', 'max')\n",
        ").reset_index()\n",
        "\n",
        "# Calculer la moyenne de la quantité vendue par catégorie (ou un autre critère de regroupement)\n",
        "category_quantity_insights = merge_df.groupby('category').agg(\n",
        "    average_quantity_sold=('qty', 'mean'),\n",
        "    min_quantity_sold=('qty', 'min'),\n",
        "    max_quantity_sold=('qty', 'max')\n",
        ").reset_index()\n",
        "\n",
        "# Trier par la moyenne de la quantité vendue pour obtenir des aperçus sur le comportement des clients\n",
        "category_quantity_insights_sorted = category_quantity_insights.sort_values(by='average_quantity_sold', ascending=False)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(category_quantity_insights_sorted)\n",
        "\n",
        "# Enregistrer les résultats dans un fichier CSV si nécessaire\n",
        "category_quantity_insights_sorted.to_csv('/content/quantity_insights_by_category_2023.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBF2MjNXURWg",
        "outputId": "bd08dfa9-6b5b-49e3-8dd0-9c27a679cfeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           category average_quantity_sold min_quantity_sold max_quantity_sold\n",
            "11          Outdoor              2.674419                 1                 4\n",
            "13          Storage              2.647059                 1                 4\n",
            "1           Bedroom              2.646341                 1                 4\n",
            "4         Furniture              2.632743                 1                 4\n",
            "3       Electronics              2.588235                 1                 4\n",
            "10           Office              2.570175                 1                 4\n",
            "0          Bathroom                  2.56                 1                 4\n",
            "9       Living Room              2.534682                 1                 4\n",
            "5   Kids' Furniture              2.488889                 1                 4\n",
            "2             Decor              2.421053                 1                 4\n",
            "12             Pets              2.416667                 1                 4\n",
            "6           Kitchen               2.40991                 1                 4\n",
            "8          Lighting              2.235294                 1                 4\n",
            "7           Laundry                   2.2                 1                 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The sales 2023 sorted+ complete **"
      ],
      "metadata": {
        "id": "I0lWgIiFVOzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the unnecessary columns\n",
        "columns_to_drop = ['Qt to_avg']\n",
        "sales_2023_sorted = sales_2023_sorted.drop(columns=columns_to_drop)\n",
        "\n",
        "\n",
        "\n",
        "print(sales_2023_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Mp1qdmgAc5x3",
        "outputId": "407ff02f-9784-4ff4-c30a-0593fde352d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sales_2023_sorted' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5d7d30a5e44b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop the unnecessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolumns_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Qt to_avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msales_2023_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msales_2023_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sales_2023_sorted' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fact and dimensions**"
      ],
      "metadata": {
        "id": "WTuF29UHbh4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sales_fact (fact table)**"
      ],
      "metadata": {
        "id": "7XM3jLC-iHby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Group by order_id and calculate total quantity sold per order\n",
        "order_totals = sales_2023_sorted.groupby('order_id')['qty'].sum()\n",
        "\n",
        "# Calculate the average quantity per order\n",
        "avg_quantity_per_order = order_totals.mean()\n",
        "\n",
        "# Add a column for total_quantity_per_order (only if not already present)\n",
        "if 'total_quantity_per_order' not in sales_2023.columns:\n",
        "    sales_2023_sorted = sales_2023_sorted.merge(\n",
        "        order_totals.rename('total_quantity_per_order'),\n",
        "        on='order_id'\n",
        "    )\n",
        "\n",
        "# Add a descriptive column based on comparison to the average\n",
        "sales_2023_sorted['compare_to_avg'] = sales_2023_sorted['total_quantity_per_order'].apply(\n",
        "    lambda x: 'Above Average' if x > avg_quantity_per_order else 'Below Average'\n",
        ")\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(f\"Average quantity per order in 2023: {avg_quantity_per_order:.2f}\")\n",
        "print(sales_2023_sorted.head())\n",
        "# Save the updated sales_2023 DataFrame to a CSV file\n",
        "sales_2023_sorted.to_csv(\"sales_2023_updated.csv\", index=False)\n",
        "\n",
        "# Optional: print a confirmation message\n",
        "print(\"File has been saved as 'sales_2023_updated.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u84zNQsvoSOp",
        "outputId": "3f12093c-c011-43d1-f086-48473732db33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average quantity per order in 2023: 2.55\n",
            "   order_id order_date product_id qty  discount_percentage  unit_price  \\\n",
            "0  IN-44633 2023-01-19       P-11   1                  0.1       24.99   \n",
            "1  IN-43488 2023-01-19       P-18   4                  0.4       45.00   \n",
            "2  IN-47618 2023-01-19       P-18   2                  0.2       45.00   \n",
            "3  IN-44672 2023-01-19       P-23   3                  0.4        9.99   \n",
            "4  IN-47796 2023-01-19       P-22   3                  0.3      159.00   \n",
            "\n",
            "  store_id  revenue total_quantity_per_order compare_to_avg  \n",
            "0    IK-23   22.491                        1  Below Average  \n",
            "1    IK-19  108.000                        4  Above Average  \n",
            "2     IK-9   72.000                        2  Below Average  \n",
            "3     IK-4   17.982                        3  Above Average  \n",
            "4    IK-17  333.900                        3  Above Average  \n",
            "File has been saved as 'sales_2023_updated.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Rename columns to align with the fact table schema\n",
        "sales_fact = sales_2023_sorted.copy()\n",
        "\n",
        "sales_fact.rename(columns={\n",
        "    'order_id': 'sales_id',               # Primary Key (PK)\n",
        "    'qty': 'quantity_sold',               # Number of units sold\n",
        "}, inplace=True)\n",
        "\n",
        "# Step 2: Adjust column selection to include 'Qt sold compared to_avg'\n",
        "columns_to_keep = [\n",
        "    'sales_id',                           # Primary Key (PK)\n",
        "    'product_id',                         # Foreign Key (FK) to products_dim\n",
        "    'store_id',                           # Foreign Key (FK) to stores_dim\n",
        "    'order_date',                         # Foreign Key (FK) to time_dim\n",
        "    'quantity_sold',                      # Number of units sold\n",
        "    'unit_price',                         # Unit price of product\n",
        "    'revenue',                            # Total revenue\n",
        "    'discount_percentage',                # Discount applied\n",
        "    'compare_to_avg'                      # Descriptive attribute\n",
        "]\n",
        "\n",
        "# Check if all columns exist before selection\n",
        "missing_columns = [col for col in columns_to_keep if col not in sales_fact.columns]\n",
        "if missing_columns:\n",
        "    print(f\"Missing columns: {missing_columns}\")\n",
        "else:\n",
        "    # Select relevant columns for the fact table\n",
        "    sales_fact = sales_fact[columns_to_keep]\n",
        "\n",
        "    # Step 3: Save the fact table as a CSV file\n",
        "    sales_fact.to_csv('sales_fact.csv', index=False)\n",
        "\n",
        "    # Step 4: Download the CSV file to your PC\n",
        "    from google.colab import files\n",
        "    files.download('sales_fact.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9eGVdWbMbrDE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "64880e64-97f0-405e-eee5-8324f7fe0d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0e779646-4195-4f42-a8ab-67090ce90df4\", \"sales_fact.csv\", 117980)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRODUCTS DIMENSION **TABLE**"
      ],
      "metadata": {
        "id": "yzM1M_qFqIhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Verify the columns in products_df\n",
        "print(products_df.columns)\n",
        "\n",
        "# Step 2: Select and create the products dimension table\n",
        "products_dim = products_df[['product_id', 'product_name', 'category', 'subcategory', 'unit_pice']]\n",
        "\n",
        "# Step 3: Save the products dimension table to a CSV file\n",
        "products_dim.to_csv('products_dimension.csv', index=False)\n",
        "\n",
        "# Step 4: Download the products dimension CSV file\n",
        "from google.colab import files\n",
        "files.download('products_dimension.csv')\n",
        "\n",
        "print(\"Products dimension table saved and downloaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "eoxDh04gp30d",
        "outputId": "3236212d-c866-43ca-9df4-95a4ff3dac2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['product_id', 'product_name', 'category', 'subcategory', 'unit_pice'], dtype='object')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4693296d-3c65-4d63-b60a-dfa6b72e9776\", \"products_dimension.csv\", 8431)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Products dimension table saved and downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Verify the columns in stores_df\n",
        "print(stores_df.columns)\n",
        "\n",
        "# Step 2: Select and create the stores dimension table\n",
        "stores_dim = stores_df[['store_id', 'store_name', 'city', 'country']]\n",
        "\n",
        "# Step 3: Save the stores dimension table to a CSV file\n",
        "stores_dim.to_csv('stores_dimension.csv', index=False)\n",
        "\n",
        "# Step 4: Download the stores dimension CSV file\n",
        "from google.colab import files\n",
        "files.download('stores_dimension.csv')\n",
        "\n",
        "print(\"Stores dimension table saved and downloaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "WDGuR8lVqN4A",
        "outputId": "1ee4f22a-2391-4028-a444-4a7142dfb02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['store_id', 'store_name', 'city', 'country'], dtype='object')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_64734a64-615f-4f3d-b6d6-012e6784e8db\", \"stores_dimension.csv\", 4074)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stores dimension table saved and downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Verify the columns in inventory_df\n",
        "print(inventory_df.columns)\n",
        "\n",
        "# Step 2: Select and create the inventory dimension table\n",
        "inventory_dim = inventory_df[['iventory_id', 'product_id', 'current_stock', 'reorder_level', 'stock_status']]\n",
        "\n",
        "# Step 3: Save the inventory dimension table to a CSV file\n",
        "inventory_dim.to_csv('inventory_dimension.csv', index=False)\n",
        "\n",
        "# Step 4: Download the inventory dimension CSV file\n",
        "from google.colab import files\n",
        "files.download('inventory_dimension.csv')\n",
        "\n",
        "print(\"Inventory dimension table saved and downloaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "0nvkp9wPqyT2",
        "outputId": "394d4a52-272a-4d37-f355-bea2022c78c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['iventory_id', 'product_id', 'current_stock', 'reorder_level',\n",
            "       'stock_status'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_42cc9cde-3504-4901-97fd-0fefde7c33be\", \"inventory_dimension.csv\", 4638)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inventory dimension table saved and downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Make sure 'order_date' is in datetime format\n",
        "sales_2023_sorted['order_date'] = pd.to_datetime(sales_2023_sorted['order_date'])\n",
        "\n",
        "# Step 2: Extract the required components (year, quarter, month, day)\n",
        "time_dim = pd.DataFrame()\n",
        "\n",
        "# Create the order_date_id as a unique identifier (you can use the index or a custom ID if needed)\n",
        "time_dim['order_date_id'] = sales_2023_sorted['order_date'].dt.date.unique()\n",
        "\n",
        "# Extract year, quarter, month, and day\n",
        "time_dim['order_date'] = pd.to_datetime(time_dim['order_date_id'])\n",
        "time_dim['year'] = time_dim['order_date'].dt.year\n",
        "time_dim['quarter'] = time_dim['order_date'].dt.quarter\n",
        "time_dim['month'] = time_dim['order_date'].dt.month\n",
        "time_dim['day'] = time_dim['order_date'].dt.day\n",
        "\n",
        "# Step 3: Save the time dimension table to a CSV file\n",
        "time_dim.to_csv('time_dimension.csv', index=False)\n",
        "\n",
        "# Step 4: Download the time dimension CSV file\n",
        "from google.colab import files\n",
        "files.download('time_dimension.csv')\n",
        "\n",
        "print(\"Time dimension table saved and downloaded!\")\n"
      ],
      "metadata": {
        "id": "h_85lSN_slDf",
        "outputId": "ebf2f934-336e-4312-b3a9-049fff676bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8509142e-1aca-491b-9642-25b4f2ae2c9e\", \"time_dimension.csv\", 2103)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time dimension table saved and downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "StWig6M5alN3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}